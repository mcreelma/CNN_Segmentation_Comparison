{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "from Cloud_Loader import CloudDataset\n",
    "# from GPUtil import showUtilization as gpu_usage\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from pathlib import Path\n",
    "from PIL import Image\n",
    "from UNET_Network import UNET\n",
    "import time\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader, sampler\n",
    "from torch import cuda, nn\n",
    "from torchmetrics import ConfusionMatrix\n",
    "import numpy as np"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Adjustables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Minibatch Size\n",
    "batch_size = 150\n",
    "# Biggest so far without breaking: 100"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Import Data"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Import and Split Data\n",
    "\n",
    "Keeping the same split so as to have consistency between the two datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " training dataset length: 6940\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6940"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Set the base path and load in the dataset \n",
    "base_path = Path('Data/95-cloud_training')\n",
    "\n",
    "data = CloudDataset(base_path/'train_red', \n",
    "                    base_path/'train_green', \n",
    "                    base_path/'train_blue', \n",
    "                    base_path/'train_nir',\n",
    "                    base_path/'train_gt')\n",
    "\n",
    "\n",
    "# Split into training and testing data\n",
    "train_ds , valid_ds , test_ds = torch.utils.data.random_split(data, [ 0.6 , 0.2 , 0.2 ],  generator=torch.Generator().manual_seed(42))\n",
    "\n",
    "test_dl = DataLoader(test_ds ,\n",
    "                                    batch_size = batch_size, \n",
    "                                    shuffle = True)\n",
    "\n",
    "print(f' training dataset length: {len(test_ds)}')\n",
    "\n",
    "display(len(test_ds))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model Evaluation"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load the previous weights"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " Running on cuda:0 \n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<All keys matched successfully>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# set the path to the modeled weights\n",
    "path = 'UNETRaw/UNET_Raw_Weights.pth'\n",
    "# path = 'UNET_Raw_Weights.pth'\n",
    "\n",
    "# send everything to the GPU if available\n",
    "dev = torch.device('cuda:0' if torch.cuda.is_available() else 'cpu')\n",
    "print(f' Running on {dev} ')\n",
    "\n",
    "# apply 4 chanels in to binary mask\n",
    "unet = UNET(4 , 2).to(dev)\n",
    "\n",
    "# Load previous weights\n",
    "unet.load_state_dict(torch.load(path))\n",
    "\n",
    "# print out the network design\n",
    "# unet.eval()\n",
    "\n"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define the Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def acc_metric(predb, yb):\n",
    "    return (predb.argmax(dim=1) == yb.to(dev)).float().mean()\n",
    "\n",
    "def test_loop(model, test_dl , loss_fn):\n",
    "    start = time.time() \n",
    "    model.to(dev) # Send the model to the device\n",
    "    test_loss , test_acc = [] , [] # create vectors for loss and acc\n",
    "    best_acc = 0.0\n",
    "    model.train(False) # We are not updating weights\n",
    "    dataloader = test_dl\n",
    "\n",
    "    # set losses and accuracies to 0 \n",
    "    running_loss = 0.0 \n",
    "    running_acc = 0.0\n",
    "    step = 0\n",
    "\n",
    "    # iterate over data\n",
    "    for x, y in dataloader:\n",
    "        step += 1\n",
    "        if step % 2 == 0:\n",
    "            # clear_output(wait=True)\n",
    "             torch.cuda.empty_cache()\n",
    "        x = x.to(dev)\n",
    "        y = y.to(dev)\n",
    "        with torch.no_grad():\n",
    "            outputs = model(x)\n",
    "            loss = loss_fn(outputs, y.long())\n",
    "    \n",
    "        # stats - whatever is the phase\n",
    "            acc = acc_metric(outputs, y)\n",
    "\n",
    "            running_acc  += acc*dataloader.batch_size\n",
    "            running_loss += loss*dataloader.batch_size \n",
    "            # print(step % 100)\n",
    "        # if step % 10 == 0:\n",
    "        #     clear_output(wait=True)\n",
    "\n",
    "\n",
    "    test_loss = running_loss / len(dataloader.dataset)\n",
    "    test_acc = running_acc / len(dataloader.dataset)\n",
    "    \n",
    "    time_elapsed = time.time() - start\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(time_elapsed // 60, time_elapsed % 60))\n",
    "    print(f'Test Loss: {test_loss}')\n",
    "    print(f'Test Accuracy: {test_acc}')\n",
    "    \n",
    "    return test_loss , test_acc   "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Run the Test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training complete in 1m 31s\n",
      "Test Loss: 0.11159547418355942\n",
      "Test Accuracy: 0.9708736538887024\n"
     ]
    }
   ],
   "source": [
    "loss_fn = nn.CrossEntropyLoss()\n",
    "test_loss , test_acc = test_loop(unet , test_dl, loss_fn)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'test_acc' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/bsuhome/mitchcreelman/Neural_Networks/Project2/UNET_Raw_Testing.ipynb Cell 15\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bborah-compute/bsuhome/mitchcreelman/Neural_Networks/Project2/UNET_Raw_Testing.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m test_acc \u001b[39m=\u001b[39m  np\u001b[39m.\u001b[39masarray(test_acc\u001b[39m.\u001b[39mcpu())\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bborah-compute/bsuhome/mitchcreelman/Neural_Networks/Project2/UNET_Raw_Testing.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m test_loss \u001b[39m=\u001b[39m  np\u001b[39m.\u001b[39masarray(test_loss\u001b[39m.\u001b[39mcpu())\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bborah-compute/bsuhome/mitchcreelman/Neural_Networks/Project2/UNET_Raw_Testing.ipynb#X20sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m display(test_acc)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'test_acc' is not defined"
     ]
    }
   ],
   "source": [
    "test_acc =  np.asarray(test_acc.cpu())\n",
    "test_loss =  np.asarray(test_loss.cpu())\n",
    "display(test_acc)\n",
    "display(test_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([150, 2, 384, 384])"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Transfer the batch to images\n",
    "def batch_to_img(xb, idx):\n",
    "    img = np.array(xb[idx,0:3])\n",
    "    return img.transpose((1,2,0))\n",
    "\n",
    "# Predictions to of\n",
    "def predb_to_mask(predb, idx):\n",
    "    p = torch.functional.F.softmax(predb[idx], 0)\n",
    "    return p.argmax(0).cpu()\n",
    "\n",
    "xb, yb = next(iter(test_dl))\n",
    "\n",
    "with torch.no_grad():\n",
    "    predb = unet(xb.to(dev))\n",
    "predb.shape"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Confusion Matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[13889639,   348060],\n",
       "       [ 1013039,  6867662]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "array([[13889639,   348060],\n",
       "       [ 1013039,  6867662]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# confusion matrix equation\n",
    "confmat = ConfusionMatrix(task=\"binary\", num_classes=2)\n",
    "CM = np.zeros((2,2), dtype = int) # Start with 0s\n",
    "PP = np.zeros(batch_size, dtype = int)\n",
    "\n",
    "\n",
    "for i in range(batch_size):\n",
    "    # prediction\n",
    "    preds = predb_to_mask(predb, i)\n",
    "    # Mask\n",
    "    target = yb[i]\n",
    "    # matrix of prediction\n",
    "    CMi = confmat(preds, target).numpy()\n",
    "    CM += CMi # Add them all up\n",
    "\n",
    "# Calculate the percentage matrix\n",
    "Tp = np.sum(CM) # Total Pixels\n",
    "PCM = CM/Tp*100 # % of each occurance\n",
    "PCM = CM.round(decimals = 1) # Round for readability\n",
    "display(PCM)\n",
    "\n",
    "# Total Confusion Matrix (Mastix of the raw values)\n",
    "TCM = CM\n",
    "display(TCM)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Confusion Matrix Stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.float64"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Net_Acc = (test_acc*100).round(decimals = 2)  # Network Accuracy\n",
    "Net_Acc = Net_Acc.astype(float)\n",
    "Net_Loss = test_loss.astype(float)\n",
    "TP = CM[0][0]   # True positive\n",
    "FN = CM[0][1]  # False Negative\n",
    "FP = CM[1][0]   # False Positive\n",
    "TN = CM[1][1]  # True Negative\n",
    "P =  TP + FN    # Positive\n",
    "N = FP + TN    # Negative\n",
    "PP = TP+FP # Predicted Positive\n",
    "PN = FN + TN # Predicted Negative\n",
    "T = P+N     # Total population\n",
    "TPR = TP/P       # True Positivity Rate\n",
    "FNR = 1 - TPR  # False Negative Rate\n",
    "FPR = FP/N       # False Positive Rate\n",
    "TNR = 1 - FPR  # True Negative Rate\n",
    "Prev = P/(P+N) # Prevalence\n",
    "ACC = (TP+TN)/(T+N) # Accuracy\n",
    "BA = (TPR+TNR)/2 # Balanced Accuracy\n",
    "PPV = TP/PP # Positive Predictive value\n",
    "FDR = 1 - PPV # False Discovery Rate\n",
    "FOR = FN/PN # False Omission Rate\n",
    "NPV = 1 - FOR # Negative Predictive Value\n",
    "LRP = TPR/FPR # Positive likeliehood ratio\n",
    "LRN = FNR/TNR # Negative Likeliehood Ratio\n",
    "MK = PPV+NPV - 1 # Markedness, delta P\n",
    "DOR = LRP/LRN  # Diagnostic odds ratio\n",
    "TS = TP/(TP+FN+FP) # Threat Score/Critical Success Index\n",
    "MCC = np.sqrt(TPR*TNR*PPV*NPV) # Mathews Correlation Coefficient\n",
    "FM = np.sqrt(PPV*TPR) # Faowlkes-Mallows index\n",
    "F = 2*TP/(2*TP + FP + FN) # F1 Score\n",
    "BM = TPR+TNR -1 # Bookmaker Informedness\n",
    "PT = (np.sqrt(TPR*FPR)-FPR)/(TPR-FPR) # Prevalence Threshold\n",
    "type(PT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>Testing Accuracy</th>\n",
       "      <td>97.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Testing Loss</th>\n",
       "      <td>0.11159547418355942</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Positive (TP)</th>\n",
       "      <td>13889639</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Negative (FN)</th>\n",
       "      <td>348060</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Positive (FP)</th>\n",
       "      <td>1013039</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Negative (TN)</th>\n",
       "      <td>6867662</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive (P)</th>\n",
       "      <td>14237699</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative (N)</th>\n",
       "      <td>7880701</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted Positive (PP)</th>\n",
       "      <td>14902678</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Predicted Negative (PN)</th>\n",
       "      <td>7215722</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Total Population (T)</th>\n",
       "      <td>22118400</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Positivity Rate (TPR)</th>\n",
       "      <td>0.975554</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Negativity Rate (FNR)</th>\n",
       "      <td>0.024446</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Positivity Rate (FPR)</th>\n",
       "      <td>0.128547</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>True Negative Rate (TNR)</th>\n",
       "      <td>0.871453</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prevalence (Prev)</th>\n",
       "      <td>0.643704</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Accuracy (ACC)</th>\n",
       "      <td>0.691931</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Balanced Accuracy (BA)</th>\n",
       "      <td>0.923503</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive Predictive Value (PPV)</th>\n",
       "      <td>0.932023</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Discovery Rate (FDR)</th>\n",
       "      <td>0.067977</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>False Omission Rate (FOR)</th>\n",
       "      <td>0.048236</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative Positivity Rate (NPV)</th>\n",
       "      <td>0.951764</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Positive Likeliehood Ratio (LRP)</th>\n",
       "      <td>7.589092</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Negative Likeliehood Ratio (LRN)</th>\n",
       "      <td>0.028052</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Markedness (MK)</th>\n",
       "      <td>0.883787</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Diagnostic Odds Ratio (DOR)</th>\n",
       "      <td>270.53259</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Threat Score (TS)</th>\n",
       "      <td>0.910752</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Mathews Correlation Coefficient (MCC)</th>\n",
       "      <td>0.868411</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Fawlkes-Mallows Index (FM)</th>\n",
       "      <td>0.95354</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>F1 Score (F)</th>\n",
       "      <td>0.953292</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Bookmaker Informedness (BM)</th>\n",
       "      <td>0.847007</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>Prevalence Threshold (PT)</th>\n",
       "      <td>0.266324</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                      Unet\n",
       "Testing Accuracy                                     97.09\n",
       "Testing Loss                           0.11159547418355942\n",
       "True Positive (TP)                                13889639\n",
       "False Negative (FN)                                 348060\n",
       "False Positive (FP)                                1013039\n",
       "True Negative (TN)                                 6867662\n",
       "Positive (P)                                      14237699\n",
       "Negative (N)                                       7880701\n",
       "Predicted Positive (PP)                           14902678\n",
       "Predicted Negative (PN)                            7215722\n",
       "Total Population (T)                              22118400\n",
       "True Positivity Rate (TPR)                        0.975554\n",
       "False Negativity Rate (FNR)                       0.024446\n",
       "False Positivity Rate (FPR)                       0.128547\n",
       "True Negative Rate (TNR)                          0.871453\n",
       "Prevalence (Prev)                                 0.643704\n",
       "Accuracy (ACC)                                    0.691931\n",
       "Balanced Accuracy (BA)                            0.923503\n",
       "Positive Predictive Value (PPV)                   0.932023\n",
       "False Discovery Rate (FDR)                        0.067977\n",
       "False Omission Rate (FOR)                         0.048236\n",
       "Negative Positivity Rate (NPV)                    0.951764\n",
       "Positive Likeliehood Ratio (LRP)                  7.589092\n",
       "Negative Likeliehood Ratio (LRN)                  0.028052\n",
       "Markedness (MK)                                   0.883787\n",
       "Diagnostic Odds Ratio (DOR)                      270.53259\n",
       "Threat Score (TS)                                 0.910752\n",
       "Mathews Correlation Coefficient (MCC)             0.868411\n",
       "Fawlkes-Mallows Index (FM)                         0.95354\n",
       "F1 Score (F)                                      0.953292\n",
       "Bookmaker Informedness (BM)                       0.847007\n",
       "Prevalence Threshold (PT)                         0.266324"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Save Results in dictionary\n",
    "dict = {\n",
    "    'Testing Accuracy' : Net_Acc ,  \n",
    "    'Testing Loss' : Net_Loss,\n",
    "    'True Positive (TP)' : TP ,\n",
    "    'False Negative (FN)' : FN ,\n",
    "    'False Positive (FP)' : FP,\n",
    "    'True Negative (TN)' : TN ,\n",
    "    'Positive (P)' : P,\n",
    "    'Negative (N)' : N,\n",
    "    'Predicted Positive (PP)' : PP,\n",
    "    'Predicted Negative (PN)' : PN,\n",
    "    'Total Population (T) ' : T,\n",
    "    'True Positivity Rate (TPR)' : TPR,\n",
    "    'False Negativity Rate (FNR)' : FNR,\n",
    "    'False Positivity Rate (FPR)' : FPR,\n",
    "    'True Negative Rate (TNR)' : TNR ,\n",
    "    'Prevalence (Prev)' : Prev,\n",
    "    'Accuracy (ACC)': ACC,\n",
    "    'Balanced Accuracy (BA)' : BA ,\n",
    "    'Positive Predictive Value (PPV)' : PPV ,\n",
    "    'False Discovery Rate (FDR)' : FDR,\n",
    "    'False Omission Rate (FOR)' : FOR,\n",
    "    'Negative Positivity Rate (NPV)' : NPV,\n",
    "    'Positive Likeliehood Ratio (LRP)' : LRP,\n",
    "    'Negative Likeliehood Ratio (LRN)' : LRN,\n",
    "    'Markedness (MK)' : MK,\n",
    "    'Diagnostic Odds Ratio (DOR)' : DOR,\n",
    "    'Threat Score (TS)' :TS,\n",
    "    'Mathews Correlation Coefficient (MCC)' : MCC,\n",
    "    'Fawlkes-Mallows Index (FM)' : FM,\n",
    "    'F1 Score (F)' : F,\n",
    "    'Bookmaker Informedness (BM)' : BM, \n",
    "    'Prevalence Threshold (PT)' : PT,\n",
    "}\n",
    "\n",
    "df = pd.DataFrame([dict] ,\n",
    "    #  columns = 'UNet' ,\n",
    "    index = {'Unet'},\n",
    "     )\n",
    "df = df.transpose()\n",
    "# df.rename(index={'T' : 0})\n",
    "display(df)\n",
    "df.to_csv('UNETRaw/Raw_Unet_Matrix_Stats.csv')"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "fig, ax = plt.subplots(1 ,3, figsize=(15,5))\n",
    "fig_num = 50\n",
    "\n",
    "ax[0].imshow(batch_to_img(xb,fig_num))\n",
    "ax[0].get_xaxis().set_visible(False)\n",
    "ax[0].get_yaxis().set_visible(False)\n",
    "\n",
    "ax[1].imshow(yb[fig_num])\n",
    "ax[1].get_xaxis().set_visible(False)\n",
    "ax[1].get_yaxis().set_visible(False)\n",
    "\n",
    "ax[2].imshow(predb_to_mask(predb, fig_num))\n",
    "ax[2].get_xaxis().set_visible(False)\n",
    "ax[2].get_yaxis().set_visible(False)\n",
    "\n",
    "# Labels and adjustments\n",
    "column_text = '25' # text size for labels\n",
    "ax[0].set_title('Raw Image', fontsize = column_text)\n",
    "ax[1].set_title('Ground-Truth Mask', fontsize = column_text)\n",
    "ax[2].set_title('Predicted Mask', fontsize = column_text)\n",
    "plt.tight_layout()\n",
    "plt.suptitle('Test Image and Predictions',  # Set the overall title\n",
    "    fontsize = 50,# Fontsize\n",
    "    y = 1.15)  # Title position\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'np' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m/bsuhome/mitchcreelman/Neural_Networks/Project2/UNET_Raw_Testing.ipynb Cell 24\u001b[0m in \u001b[0;36m<cell line: 2>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bborah-compute/bsuhome/mitchcreelman/Neural_Networks/Project2/UNET_Raw_Testing.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=0'>1</a>\u001b[0m bs \u001b[39m=\u001b[39m \u001b[39m18\u001b[39m\n\u001b[0;32m----> <a href='vscode-notebook-cell://ssh-remote%2Bborah-compute/bsuhome/mitchcreelman/Neural_Networks/Project2/UNET_Raw_Testing.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=1'>2</a>\u001b[0m l \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39mrandom\u001b[39m.\u001b[39mrandint(batch_size , size \u001b[39m=\u001b[39m bs)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bborah-compute/bsuhome/mitchcreelman/Neural_Networks/Project2/UNET_Raw_Testing.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39mprint\u001b[39m(l)\n\u001b[1;32m      <a href='vscode-notebook-cell://ssh-remote%2Bborah-compute/bsuhome/mitchcreelman/Neural_Networks/Project2/UNET_Raw_Testing.ipynb#X32sdnNjb2RlLXJlbW90ZQ%3D%3D?line=3'>4</a>\u001b[0m fig, ax \u001b[39m=\u001b[39m plt\u001b[39m.\u001b[39msubplots(bs,\u001b[39m3\u001b[39m, figsize\u001b[39m=\u001b[39m(\u001b[39m15\u001b[39m,bs\u001b[39m*\u001b[39m\u001b[39m5\u001b[39m))\n",
      "\u001b[0;31mNameError\u001b[0m: name 'np' is not defined"
     ]
    }
   ],
   "source": [
    "bs = 18\n",
    "l = np.random.randint(batch_size , size = bs)\n",
    "print(l)\n",
    "fig, ax = plt.subplots(bs,3, figsize=(15,bs*5))\n",
    "for r , i in enumerate(l):\n",
    "    ax[r,0].imshow(batch_to_img(xb,i))\n",
    "    ax[r,1].imshow(yb[i])\n",
    "    ax[r,2].imshow(predb_to_mask(predb, i))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "NN2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.8"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "614e2a89b138c19aed45280bddef6b308cec2beba378502290f73bdd661f1f77"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
